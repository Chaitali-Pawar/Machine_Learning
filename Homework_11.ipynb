{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitali-Pawar/Machine_Learning/blob/master/Homework_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UkwzS7er4jDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7be8fc25-18fb-4e52-acd4-00983e70f43a"
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.model_selection\n",
        "import scipy.io\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "files = os.listdir(\"./data\")\n",
        "# Number of folds\n",
        "nfold=10\n",
        "\n",
        "kf=sklearn.model_selection.KFold(n_splits=nfold,shuffle=True)\n",
        "\n",
        "acc=np.zeros((59,nfold))\n",
        "\n",
        "i =0\n",
        "for file in files:\n",
        "  \n",
        "  index =((re.search('Ch_(.*).mat',file)).group(1))\n",
        "  mat = scipy.io.loadmat(file)\n",
        "  X = mat['Ch_Matrix']\n",
        "  y=mat['y']\n",
        "  y= np.ravel(y)\n",
        "  # Loop over the folds\n",
        "  for isplit,Ind in enumerate(kf.split(X)):\n",
        "    #print(\"fold = %d \"%isplit)\n",
        "\t # Get the training data in the split\n",
        "    Itr,Its=Ind\n",
        "\t\n",
        "\t#Xtr,Xts,Ytr,Yts = train_test_split(X,y,test_size=0.33,shuffle=True) \n",
        "    Xtr = X[Itr]\n",
        "    Ytr = y[Itr]\n",
        "    Xts = X[Its]\n",
        "    Yts = y[Its]\n",
        "    #Scale data to range of -1 and +1\n",
        "    Xtr_scale = np.interp(Xtr,(Xtr.min(),Xtr.max()),(-1,+1))\n",
        "    Xts_scale = np.interp(Xts,(Xts.min(),Xts.max()),(-1,+1))\n",
        "    svc = svm.SVC(probability=False,  kernel='rbf', C=2.8, gamma=.0073,verbose=10)\n",
        "    svc.fit(Xtr_scale,Ytr)\n",
        "    yhat = svc.predict(Xts_scale)\n",
        "    acc[int(index),isplit] =np.mean(yhat == Yts)\n",
        "\n",
        "#get the mean of accuracies over all splits\n",
        "acc_mean=np.mean(acc,axis=1)\n",
        "\n",
        "#pick the one with max accuracy\n",
        "print ('Max Accuracy is {0:f}'.format(np.max(acc_mean)))\n",
        "\n",
        "#Maximum Accuracy is for channel\n",
        "print ('Channel with max accuracy is : {0:d}'.format(np.argmax(acc_mean)))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Max Accuracy is 0.542333\n",
            "Channel with max accuracy is : 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AJa3qV5gsdF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "5189d6e4-2209-436f-cb26-489bf85b32c2"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#question 1\n",
        "import numpy as np\n",
        "X = np.array([[3,2,1],\n",
        "             [2,4,5],\n",
        "             [1,2,3],\n",
        "             [0,2,5]])\n",
        "X_mean = np.mean(X)\n",
        "print('Mean is : {0:f}'.format(np.mean(X)))\n",
        "\n",
        "# Sample Covariance\n",
        "Q = np.cov(X)\n",
        "print('Sample CoVariance is :')\n",
        "print(Q)\n",
        "\n",
        "# compute eigen values and vectors\n",
        "Values , Vectors = np.linalg.eig(Q)\n",
        "print('Eigen Values :')\n",
        "print(Values)\n",
        "\n",
        "print('Eigen Vectors : ')\n",
        "print (Vectors)\n",
        "\n",
        "# find the pca coefficents corresponding to the samples in X\n",
        "# compute x - xmean\n",
        "Mean_diff = X - X_mean\n",
        "Pca_Coeff = Vectors.T.dot(Mean_diff)\n",
        "print(\"PCA Coefficents :\")\n",
        "print(Pca_Coeff)\n",
        "X_new = np.zeros(4,3)\n",
        "# reconstruct the original samples from the pca coefficents :\n",
        "for i in range(4):\n",
        "  for j in range(3):\n",
        "    X_new[i][j] = X_mean + np.sum()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean is : 2.500000\n",
            "Sample CoVariance is :\n",
            "[[ 1.         -1.5        -1.         -2.5       ]\n",
            " [-1.5         2.33333333  1.5         3.66666667]\n",
            " [-1.          1.5         1.          2.5       ]\n",
            " [-2.5         3.66666667  2.5         6.33333333]]\n",
            "Eigen Values :\n",
            "[ 1.05080582e+01  1.58608435e-01  1.10146918e-16 -1.80894799e-16]\n",
            "Eigen Vectors : \n",
            "[[-0.30836823 -0.07006451  0.26482046 -0.90423089]\n",
            " [ 0.46006744  0.82966135  0.28518182 -0.12963556]\n",
            " [ 0.30836823  0.07006451 -0.87590683 -0.38568866]\n",
            " [ 0.77340547 -0.54940329  0.28518182 -0.12963556]]\n",
            "PCA Coefficents :\n",
            "[[-2.78028385  0.30339842  3.70041873]\n",
            " [ 0.81854852  1.51919367  0.84077417]\n",
            " [ 0.59072501  0.59072501  0.59072501]\n",
            " [ 0.51532422  0.51532422  0.51532422]]\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q5awr14hJ5H6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#question no 3 find the optimal number of PCS\n",
        "mu ,V = PCA(X)\n",
        "# V is the PCS\n",
        "iterations = V.shape[1]\n",
        "acc = np.zeros(iterations)\n",
        "for i in range(iterations):\n",
        "  clf = Classifier()\n",
        "  #Split the data into train and test\n",
        "  Xtr,Xts,Ytr,Yts = train_test_split(X,y,test_size=0.25,shuffle=True)\n",
        "  pca = PCA(n_components=i)\n",
        "  pca.fit(Xtr)\n",
        "  #transform the data\n",
        "  Z_tr = pca.transform(Xtr)\n",
        "  Z_ts = pca.transform(Xts)\n",
        "  #fit\n",
        "  clf.fit(Ztr,ytr)\n",
        "  yhat = clf.predict(Zts)\n",
        "  acc[i] = np.mean(yhat == yts)\n",
        "optimal_number_of_components = np.argmax(acc)\n",
        "print(optimal_number_of_components)\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNKxjKIBPgZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "502f3b1b-d0e1-403e-c445-63b1bf96d6b3"
      },
      "cell_type": "code",
      "source": [
        "#question 4:\n",
        "\n",
        "#fit the PC model with first 500 images and 5 components\n",
        "Y = reshape(X[0:500,:],shape)\n",
        "pca = PCA(n_components =5)\n",
        "pca.fit(Y)\n",
        "#create an array of approximations of remaining 500\n",
        "Y = reshape(X[500:1000],shape)\n",
        "Z =pca.transform(Y)\n",
        "Yhat = pca.inverse_transform(Z)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 5 6]\n",
            " [7 8 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GbZaaZgfXWPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#question 5\n",
        "U,s,Vtr = svd(Z,full_matrices=False)\n",
        "#number of Principal Components\n",
        "number_Of_PC = Vtr\n",
        "#Mean of data\n",
        "X_mean = np.mean(X,axis=0)\n",
        "#compute proportion of variance which is s sqaure\n",
        "Variance = s ** 2\n",
        "Proportion_of_Variance = np.cumsum(Variance)/np.sum(Variance)\n",
        "Variance_Above_90 = np.ravel(np.where(Proportion_of_Variance>90))\n",
        "#to transform Z we use U*s\n",
        "#to compute number of Principal Components\n",
        "number_of_components = Variance_Above_90[0]\n",
        "#Approximation of Xhat\n",
        "Xhat = (U[:,:number_of_components] * S[None,:numbr_of_components])dot(Vtr[:number_of_components,:]) +X_mean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5S3JP8G85a18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "54ead266-2b52-4627-8c3f-d43c7654db31"
      },
      "cell_type": "code",
      "source": [
        "top_5_accuracies_index = np.argsort(acc_mean)[-5:];\n",
        "print ('Max Accuracy is {0:f}'.format(np.max(acc_mean)))\n",
        "print ('Channel with max accuracy is : {0:d}'.format(np.argmax(acc_mean)))\n",
        "print(np.argsort(acc_mean)[-5:])\n",
        "top_five_accuracies = np.zeros(5)\n",
        "for i in top_5_accuracies_index:\n",
        "  print(acc_mean[i])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Accuracy is 0.542333\n",
            "Channel with max accuracy is : 51\n",
            "[10 23 19 30 51]\n",
            "0.5373595592082987\n",
            "0.5382830055098962\n",
            "0.5396255938272745\n",
            "0.5403140743476877\n",
            "0.5423333435938478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vtzz5-L_AFte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "folder = './'\n",
        "for the_file in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, the_file)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "csB-laIjA9Gt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}